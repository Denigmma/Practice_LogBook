# Диалог на собеседовании

Берем бинарную классификацию, напишите для них алгоритм,  
формулы — которые будете использовать, объясните, что происходит.

Есть такие значения:  
x = (x1, x2, …, xm) ∈ Rm; y ∈ {0, 1}; D = {(x, y)}; n = len(D)

## Формула (функция алгоритма):

h(x) = P(y=1|x,w,b) = sigmoid(w^T x + b)  
sigmoid(t) = 1 / (1 + e^-t)

## Лосс, функционал:

loss = - (1/m) SUM[i=1,m](y_i * ln(h) + (1-y_i) * ln(1-h))

entropy(ksi) = - sum p_i * log(p_i)

ksi — случайная величина

## Если y (target) — это вероятность (клика = клики / показы), y ∈ [0, 1]

Какой лосс нужен в такой ситуации?

Та же кросс-энтропия, менять ничего не нужно.

## Метод оптимизации: градиентный спуск.

dloss/dw = (1/m) SUM(sigmoid(w^T x + b) - y_i)

w = w - alpha * dloss/dw

## Условия работы алгоритма:

1) существование производной  
2)...  
(тут недочет, нужно было больше рассказать)

## Допустим, есть два алгоритма: baseline, new_method

Как бы выглядел пайплайн для сравнения качества двух моделей.

Посмотреть на метрики, сравнить на кросс-валидации.

D = датасет, надо его разбить на фолды.

d_i формируется

k fold, делим на k частей. Данные разбиваются без пересечений, одинакового размера.

train / test / val split

Нужны сами метрики: accuracy, precision, recall, f1, focal loss

f1 = 2 * (p * r) / (p + r)

Замеряем кросс-энтропию на разных фолдах.

ce(baseline, test) = alpha  
ce(new_method, test) = beta

alpha < beta?

Новый метод выиграл, покатим в прод? На что мы должны смотреть, на что обратить внимание?

f1(baseline) = 0.8  
f1(new_method) = 0.81

Катим в прод?


# Комментарии к интервью

- **Алгоритмическое решение**  
  Тут частный случай — крайний случай про пустой список действительно его надо обрабатывать. Часть решения содержит копипасту, что минорно, но не очень хорошо. Это тоже оценивается. И вот эти множественные прислания — вкусовщина, но, честно говоря, тоже минорное замечание. Остальное всё отлично.

- **Линейное решение**  
  По поводу линейного решения предлагаю подумать на досуге — это, вообще говоря, полезно. На секции MLP это не имеет никакого значения. Вернее, если бы вы придумали алгоритм, то это был бы большой плюс. В остальном предлагаю в качестве тренировки дома подумать.

- **Опыт в ML и математические формулы**  
  Про опыт у ML: про математику здесь вопросов нет. Формула записана верно, лосс — верно. Там отпечатки бывают у всех. Здесь вопросов нет, энтропия окей, вспомнилась с трудом, но да.

- **Вероятностный лосс и оптимизация**  
  Вы правильно отметили, что вероятностный лосс оптимизируется при переходе на непрерывный таргет — это отлично. По поводу метода оптимизации (градиентный спуск) всё верно, но хотелось бы чуть больше услышать про условия работы алгоритма.

- **Практические условия применения**  
  Стоит прочитать про практические вопросы и условия применения: например, когда мы достигаем глобального минимума и когда он нам гарантируется. Имеются в виду ограничения, чтобы не искать градиент, когда он близок к нулю, а останавливать процесс при достижении некоторого ε.

- **Условия сходимости**  
  Здесь можно упомянуть условия Робина–Карпа и общие критерии сходимости: в каких случаях алгоритм сходится к глобальному оптимуму, а не застревает в локальном.

- **Сравнение алгоритмов**  
  По поводу сравнения двух алгоритмов вы всё правильно описали, но советую добавить информацию об A/B-тестировании и методах статистической оценки гипотез. Когда есть контрольная и тестовая выборки, как принимается решение — об этом подробно в Яндекс.Учебнике по e-mail (есть ссылки на статьи).

- **Градиентный спуск**  
  Про градиентный спуск можно почитать в том же источнике. Если остались вопросы — туда же.

- **Итоговая оценка**  
  Секция пройдена. Детали раскрыть не могу — это получит рекрутер. Но вы можете сделать выводы по фидбэку. Спасибо вам огромное.
