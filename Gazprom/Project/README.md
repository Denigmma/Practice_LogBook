# Прогнозирование отказов оборудования и аварийных ситуаций в газовой и нефтяной промышленности на специализированных установках

---

## Информация о проекте

**Выполнил:** Мурадян Денис Степанович  
**Разработано для конкурса проектов от ПАО "Газпром" в рамках студенческой олимпиады 2024-2025**

Проект разработан для повышения безопасности и эффективности эксплуатации
оборудования в газовой и нефтяной промышленности посредством интеллектуального мониторинга. Система анализирует данные в режиме реального времени, позволяя своевременно выявлять риски отказа оборудования.

---

## Краткое описание проекта

Данный проект представляет собой систему для выявления риска отказа оборудования на специализированных установках, используя
искусственный интеллект в режиме реального времени. Нейронная сеть анализирует
поступающие данные с датчиков и оценивает вероятность отказа оборудования в течение ближайшего времени, тем самым
помогая оперативно реагировать на потенциальные аварийные ситуации.
Искусственная симуляция и генерация датасетов используются для демонстрации работоспособности решения.

### Важность

- **Безопасность:** Система позволяет существенно повысить безопасность работы персонала, своевременно выявляя потенциальные угрозы и предотвращая аварийные ситуации.
- **Экономическая эффективность:** Предотвращение аварий снижает финансовые потери, связанные с ремонтными работами, простоями оборудования и экологическими штрафами.
- **Экологическая устойчивость:** Оптимизация работы объектов снижает риск экологических катастроф, минимизируя утечки и выбросы, что способствует сохранению окружающей среды.


### Актуальность

В условиях постоянно растущих требований к надежности инфраструктуры и безопасности эксплуатации, данное решение позволяет оперативно 
реагировать на изменения в состоянии оборудования. Система обеспечивает непрерывный мониторинг и предсказание отказов,
что является критически важным для газопроводов, нефтедобывающих предприятий и других объектов энергетического комплекса.

### Целевая аудитория

- **Операторы и инженеры:** Система предоставляет оперативную информацию, позволяющую быстро принимать решения о профилактическом обслуживании и устранении неисправностей.
- **Руководители и менеджеры по эксплуатации:** Инструмент для оптимизации расходов и повышения надежности работы объектов, позволяющий минимизировать затраты на аварийный ремонт и простои.
- **Исследователи и специалисты по инновациям:** Платформа для демонстрации и внедрения передовых алгоритмов глубокого обучения и анализа потоковых данных, способствующая развитию интеллектуальных систем управления инфраструктурой.

---

## Структура проекта

```plaintext
Project/
├── app/
│   ├── __init__.py
│   ├── main.py               # Серверное приложение на базе FastAPI, реализующее REST API для предсказаний и дашборда
│   ├── inference.py          # Функции для предобработки данных и вызова модели для предсказаний
│   └── dashboard.html        # HTML-страница для визуального контроля текущих показателей риска отказа.
├── data/
│   ├── generate_dataset.py   # Формирует синтетический датасет для обучения и демонстрации работы системы, имитируя поступление данных с датчиков и их отказа
│   ├── sensor_train_data.csv # Датасет для обучения модели
│   ├── sensor_val_data.csv   # Датасет для валидации модели
│   └── sensor_test_data.csv  # Датасет для тестирования модели
├── model/
│   ├── __init__.py
│   ├── model.py              # Скрипт для подготовки данных, построения и обучения модели, а также логирования параметров обучения
│   ├── logs/
│   │   ├──total_log.txt      # Информация о модели и отслеживаемых параметрах
│   │   └──training_log.csv   # Информация о модели на каждой эпохе
│   └── saved_models/
│       └── gru_model.h5      # Сохранённая обученная модель
├── simulation_data/      
│   └── data_simulator.py     # Скрипт для симуляции поступления данных в режиме реального времени
└── README.md                 # Документация проекта
```

---

## Принцип работы системы

Система работает по следующей схеме:

- **Получение данных:** Поступление данных с датчиков в режиме реального времени. Для демонстрации работы используется синтетическая генерация данных с помощью `generate_dataset.py` для подготовки обучающего, валидационного, тестового датасетов и `data_simulator.py` для имитации поступления данных с датчиков.
  
- **Обработка данных:** Данные проходят нормализацию и преобразование в нужный формат в модуле `inference.py`, после чего поступают на вход обученной модели.

- **Предсказание отказа:** Загруженная и обученная GRU-модель анализирует последовательности из 20 отсчетов (с 5 параметрами - датчиками) и оценивает вероятность отказа оборудования. 20 отсчетов было выбрано для лучшего понимания модели - контекста работы установки.

- **Доступ к результатам:** Сервер, реализованный в `app/main.py`, предоставляет REST API для получения предсказаний и отображения дашборда, где можно контролировать текущие показатели риска для каждой установки.

### Основные модули и их роль

- **app/main.py**  
  Запускает сервер FastAPI, загружает сохранённую модель и реализует следующие API-эндпоинты:
  - **/predict:** Принимает последовательность данных с датчиков и возвращает рассчитанную вероятность отказа.
  - **/update и /predictions:** Обновляют и хранят последние предсказания для каждой установки.
  - **/dashboard:** Отдает HTML-страницу для визуального контроля показателей риска отказа.

- **app/inference.py**  
  Содержит функции для нормализации входных данных и выполнения предсказания модели.

- **data/generate_dataset.py**  
  Формирует синтетический датасет, имитируя поступление данных с датчиков. Для каждой из 10 установок задаются базовые параметры (давление, температура, вибрация, расход газа), которые затем изменяются под воздействием случайных колебаний и событий, имитирующих начало отказа.

- **model/model.py**  
  Отвечает за:
  - Формирование последовательностей данных и разметку сценариев отказа.
  - Построение GRU-модели для бинарной классификации (отказ/без отказа).
  - Обучение модели с логированием основной информации об обучении в файлы `total_log.txt` и `training_log.csv`, расположенные в каталоге `model/logs`.
  
- **data_simulator.py**  
  Имитирует поток данных, формируемых на основе датасета, и отправляет их на сервер для демонстрации работы системы в условиях, приближенных к реальным.

---

## Датасет

### Структура и формирование данных

Датасет формируется с помощью `generate_dataset.py` и используется для обучения модели,
ее валидации и демонстрации работоспособности системы. Каждая запись датасета содержит следующие признаки:

- **timestamp:** Временная метка (например, `2025-03-15 11:00:01`).
- **segment_id:** Идентификатор установки (A1, A2, …, A10).
- **pressure:** Давление, исходные значения около 7.0–9.0 bar с постепенным изменением.
- **temperature:** Температура, исходные значения около 20.0–25.0 °C.
- **vibration:** Уровень вибрации, исходные значения около 0.03–0.07 м/с.
- **flow_rate:** Расход газа, исходные значения около 150.0–250.0 м³/час.

### Принцип формирования данных

- **Нормальные условия работы:**
Для каждой установки задаются базовые значения, которые затем подвергаются естественному дрейфу и случайным колебаниям для имитации реалистичной работы.
- **Симуляция отказа:**
Для отдельных установок в случайный момент запускается предписание, имитирующее начало отказа.
Это может выражаться в резком изменении давления, уменьшении пропускаемости, последовательном повышении температуры или 
вибрации - что демонстрирует неправильную работу установки и последующий выход из строя.
Предписание для случайной установки выдается с учетом реалистичных условий и вероятность отказа крайне низкая 
(0.5%) - что подчеркивает важность обнаружения даже единичных случаев.
Из 10 000 нормальных показаний важно выявить даже единственный отказ, так как его обнаружение имеет критическое значение.
- **Предписания для установок:**
На основании изменений параметров системе присваивается метка риска отказа, что позволяет операторам своевременно принимать меры по профилактике.

---

## Создание и обучение модели

### Выбор архитектуры

В задачах анализа данных с датчиков, где измерения производятся каждую секунду,
крайне важно учитывать временные взаимосвязи между последовательными наблюдениями.
При работе с такими данными традиционные модели, например, MLP (Multi-Layer Perceptron),
не справляются с захватом динамики изменений, поскольку они обрабатывают данные последовательно, независимо от предыдущих показаний.

Рекуррентные нейронные сети (RNN – Recurrent Neural Network) специально созданы для анализа
последовательных данных. Они обрабатывают следующие данные на основе уже обработанных,
что делает их более подходящими для решения подобных задач.
Однако классические RNN страдают от проблемы затухания и взрыва градиента,
особенно при обработке длинных последовательностей, что затрудняет обучение модели.

В связи с этим была выбрана архитектура GRU (Gated Recurrent Unit) — усовершенствованная версия RNN,
которая благодаря внутренним механизмам управления потоком данных частично решает проблему затухания и взрыва градиента.
GRU-модель эффективна при обработке временных рядов, поскольку способна сохранять и использовать
информацию о прошлых наблюдениях, что особенно важно при анализе последовательных данных с датчиков.

### Сценарии отказа

В процессе подготовки данных в модуле `model/model.py` реализованы следующие сценарии, указывающие на риск отказа:
- Резкое увеличение давления на протяжении последовательности (рост более 20%).
- Последовательное повышение температуры в условиях устойчиво высокого давления.
- Сохранение высокого уровня давления при снижении расхода газа.
- Сочетание постоянного высокого уровня вибрации с непрерывным ростом температуры.
- Дополнительные эвристические условия, учитывающие экстремальные значения отдельных параметров.

### Логирование

Основная информация об обучении модели фиксируется в файлах, расположенных в каталоге `model/logs`:
- `total_log.txt` информация о модели и ее параметрах
- `training_log.сsv` информация о параметрах в каждой эпохе

В этих файлах сохраняются данные о модели, отслеживаемых параметрах, использовании памяти и времени тренировки.

### Настройка гиперпараметров

Используемые гиперпараметры:
- **Loss function:** Focal Loss для бинарной классификации
- **Количество слоев:** 2
- **Количество нейронов:** [64, 32]
- **Метрики:** Accuracy, AUC, Precision, Recall
- **Количество эпох:** 50

### Результаты обучения

```
Type: GRU-based RNN (Sequential model)
Count layers: 2
Count neurons: [64, 32]
Loss function: <function focal_loss.<locals>.focal_loss_fixed at 0x000001C9299CEE80>
Count epochs: 50
Metrics: accuracy, <AUC name=auc>, <Precision name=precision>, <Recall name=recall>
Memory used during training: 512.71 MB
Total training time: 190.22 seconds

Baseline metrics:
Loss before training (Train): 0.0440
Loss before training (Validation): 0.0440

Final metrics:
Loss after training (Train): 0.0113
Loss after training (Validation): 0.0113
Training metrics: loss = 0.0113, accuracy = 0.9125, auc = 0.9777, precision = 0.8490, recall = 0.9178
Validation metrics: loss = 0.0113, accuracy = 0.9125, auc = 0.9777, precision = 0.8490, recall = 0.9178
```

### Интерпретация результатов

В ходе обучения GRU-модели для прогнозирования отказов оборудования получены следующие ключевые метрики,
которые позволяют оценить качество и надежность решения:

- **Loss (Потери):**  
  Значение функции потерь снизилось с 0.0440 до 0.0113 как на обучающей, так и на валидационной выборках. Это указывает на то, что модель хорошо подстроилась под данные и её предсказания максимально приближены к истинным меткам. Низкое значение loss особенно важно в задаче обнаружения редких событий, таких как отказ оборудования.

- **Accuracy (Точность):**  
  Достигнутая точность в 91.25% означает, что в 91 из 100 случаев модель верно классифицирует состояние оборудования. Такая стабильность подтверждает, что модель способна надежно различать нормальное состояние и потенциальные сбои, что критично для своевременного принятия мер.

- **AUC (Площадь под ROC-кривой):**  
  Значение AUC составило 0.9777, что демонстрирует отличную способность модели различать между классами «отказ» и «без отказа». Высокий AUC особенно важен при работе с несбалансированными данными, где позитивные случаи (отказы) встречаются редко, а точное разделение классов – залог безопасности эксплуатации.

- **Precision (Точность предсказаний отказов):**  
  Precision равный 84.90% указывает, что из всех предсказанных моделью отказов примерно 85% действительно соответствуют реальным отказам. Это снижает вероятность ложных тревог и помогает оптимизировать процессы профилактического обслуживания, исключая ненужные проверки и вмешательства.

- **Recall (Полнота обнаружения отказов):**  
  Значение recall на уровне 91.78% демонстрирует высокую чувствительность модели – она способна обнаружить большинство реальных случаев отказа. Это особенно критично в задачах, где пропуск отказа может привести к аварийной ситуации, поэтому высокая полнота позволяет минимизировать риски.

**Примеры работы модели:**

- При анализе последовательностей с постепенным повышением температуры и резким скачком давления, модель демонстрирует высокую уверенность в прогнозе отказа, позволяя оперативно проводить мероприятия по предотвращению аварий.
- В сценариях, когда изменения параметров менее выражены, но наблюдается устойчивая тенденция к ухудшению показателей, высокая чувствительность (recall) модели помогает обнаружить потенциально опасные отклонения ещё на ранней стадии.
- Снижение количества ложноположительных срабатываний (подтверждаемое значением precision) свидетельствует о том, что модель не склонна к чрезмерным срабатываниям, что важно для рационального распределения ресурсов на проверку оборудования.

Таким образом, анализ полученных метрик свидетельствуют о том, что модель надежно различает исправное состояние оборудования и потенциальный отказ.
Это подтверждает её пригодность для практического применения, позволяя оперативно реагировать на критические ситуации.
Благодаря этому повысить безопасность и снизить эксплуатационные риски.

---

## Получение и обработка данных

### REST API

Серверное приложение в `app/main.py` предоставляет REST API для:
- Приёма данных с датчиков через POST-запросы на эндпоинт `/predict`.
- Обновления и хранения последних предсказаний через эндпоинты `/update` и `/predictions`.
- Отдачи HTML-дашборда на эндпоинте `/dashboard` для визуального контроля показателей риска.

### Симуляция данных

Скрипт `data_simulator.py` формирует данные из датасета, имитируя поток информации, поступающий от датчиков в реальном времени. Полученные данные отправляются на сервер для обработки и получения предсказаний.

---


## Требования

- **Python 3.11** – убедитесь, что установлен Python указанной версии или выше.  
- **requirements** – установите необходимые зависимости и библиотеки:  
  ```bash
  pip install -r requirements.txt
  ```
- **Node.js** – необходим для онлайн-запуска с LocalTunnel. Скачайте и установите с [официального сайта](https://nodejs.org/).

---

## Запуск проекта

Проект можно запустить двумя способами: локально или онлайн с использованием LocalTunnel.

### 1. Локальный запуск

#### 1.1. Запуск сервера

Откройте терминал в корневой папке проекта и выполните команду:

```bash
python -m app.main
```

После запуска сервер будет доступен по адресу: [http://localhost:8000](http://localhost:8000)

#### 1.2. Открытие дашборда c показаниями установок

Откройте браузер и перейдите по адресу: [http://127.0.0.1:8000/dashboard](http://127.0.0.1:8000/dashboard)

На этой странице отображаются текущие предсказания вероятности отказа для каждой установки.

#### 1.3. Запуск симуляции данных

В отдельном терминале выполните:

```bash
python simulation_data/data_simulator.py
```

Скрипт начнет имитировать поток данных и отправлять их на сервер.

---

### 2. Онлайн запуск с использованием LocalTunnel

Если требуется, чтобы сервер был доступен из интернета (например, для подключения с мобильного устройства, находящегося в другой сети), выполните следующие шаги:

#### 2.1. Установка LocalTunnel

Убедитесь, что Node.js установлен, затем установите LocalTunnel глобально:

```bash
npm install -g localtunnel
```

#### 2.2. Запуск сервера

Откройте терминал в корневой папке проекта и выполните команду:

```bash
python -m app.main
```

#### 2.3. Создание публичного URL с LocalTunnel

В отдельном терминале запустите команду:

```bash
lt --port 8000
```

После этого LocalTunnel создаст публичный URL вида:

```
your url is: https://<random-string>.loca.lt
```

Для получения пароля к серверу перейдите по адресу: [https://loca.lt/mytunnelpassword](https://loca.lt/mytunnelpassword)
> Для защиты от несанкционированного доступа LocalTunnel требует вводить «Tunnel Password», который совпадает с вашим публичным IP.
Это мера безопасности, чтобы случайные пользователи не могли легко подключаться к вашему локальному серверу, если они получили ссылку. Узнать (или передать другим пользователям) пароль можно по ссылке выше.

Используйте полученный URL и пароль для доступа к серверу с любого устройства через интернет. Например, для дашборда:

```
https://<random-string>.loca.lt/dashboard
```

#### 2.4. Запуск симуляции данных

В отдельном терминале выполните:

```bash
python simulation_data/data_simulator.py
```

Это позволит имитировать поток данных и отправлять их на сервер, доступный онлайн через LocalTunnel.

> **Примечание:**  
> - Запуск через `python -m app.main` использует встроенный в `main.py` код для старта Uvicorn, что обеспечивает корректное разрешение относительных импортов и единообразное поведение.  
> - Альтернативно можно запускать сервер напрямую через Uvicorn (например, `uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload`), что удобно, если требуется изменять параметры запуска через командную строку.  
> В данном проекте рекомендуется использовать команду `python -m app.main`.

---

## Заключение

Данный проект представляет собой высокотехнологичное и инновационное решение для мониторинга и прогнозирования
отказов оборудования, основанное на анализе данных в реальном времени. Применение искусственного интеллекта, а именно GRU-модели обеспечивает
исключительную точность предсказаний, позволяя оперативно выявлять риски и предотвращать аварийные ситуации.
Искусственная генерация датасетов демонстрирует работоспособность системы в условиях, максимально приближенных к реальности.
Получение данных через REST API обеспечивает быструю и эффективную интеграцию системы в инфраструктуру предприятия.
Это решение не только существенно повышает безопасность эксплуатации объектов, но и способствует экономической эффективности,
снижая затраты на ремонт и минимизируя экологические риски. Внедрение данного проекта является значимым шагом в развитии
интеллектуальных систем управления оборудованием, отвечая актуальным требованиям современного производства и обеспечивая
надежную защиту критически важных объектов.

---
